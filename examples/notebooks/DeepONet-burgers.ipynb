{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch is using NVIDIA RTX A4000\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# NumPy\n",
    "import numpy as np\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# Misc.\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src import models\n",
    "from src.utils import seed_everything\n",
    "from src.utils.pde_utils import make_mesh\n",
    "\n",
    "# user-defined libs.\n",
    "from src.utils.plotting import Artist\n",
    "\n",
    "# Reproducibility\n",
    "seed_everything()\n",
    "# Set Device(CPU / GPU)\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"torch is using {torch.cuda.get_device_name(device)}\")\n",
    "# Metadata\n",
    "log_dir = \"logs\"\n",
    "task = \"burgers\"\n",
    "artist = Artist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole Dataset\n",
      "xs torch.Size([1024]) <class 'torch.Tensor'>\n",
      "ts torch.Size([512]) <class 'torch.Tensor'>\n",
      "ys torch.Size([1000, 1024, 512]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Load whole data\n",
    "data = np.load(\"data/Burgers_spectral_1024_512.npz\")\n",
    "xs = torch.Tensor(data[\"xs\"])\n",
    "ts = torch.Tensor(data[\"ts\"])\n",
    "ys = torch.Tensor(data[\"ys\"])\n",
    "coefficient = data[\"coefficient\"]\n",
    "print(\"Whole Dataset\")\n",
    "print(\"xs\", xs.shape, type(xs))\n",
    "print(\"ts\", ts.shape, type(ts))\n",
    "print(\"ys\", ys.shape, type(ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u: torch.Size([1000, 512])\n",
      "y: torch.Size([1000, 1024, 2])\n",
      "s: torch.Size([1000, 1024])\n",
      "train data: 800 test data: 200\n"
     ]
    }
   ],
   "source": [
    "# Create Train / Test Dataset\n",
    "Nx, Nt = len(xs), len(ts)\n",
    "mesh = make_mesh(xs, ts, stack_output=True)\n",
    "\n",
    "num_input_sensors = 512\n",
    "dim_output_sensors = 2  # (x, t)\n",
    "num_output_sensors = 1024\n",
    "idx: torch.tensor = torch.randperm(len(mesh))[:num_output_sensors]\n",
    "\n",
    "# u: (total_data, num_input_sensors)\n",
    "u_data = ys[:, :: ys.shape[1] // num_input_sensors, 0]\n",
    "# y: (Nx x Nt, 2) -> (num_output_sensors, dim_output_sensors) -> (total_data, num_output_sensors, dim_output_sensors)\n",
    "y_data = mesh[idx]  # (num_output_sensors, dim_output_sensors)\n",
    "y_data = torch.tile(\n",
    "    y_data, (len(ys), 1, 1)\n",
    ")  # (total_data, num_output_sensors, dim_output_sensors)\n",
    "# s: (total_data, num_output_sensors)\n",
    "s_data = ys.reshape(-1, Nx * Nt)[:, idx]\n",
    "\n",
    "dataset = TensorDataset(u_data, y_data, s_data)\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dataset, lengths=[0.8, 0.2], generator=torch.Generator().manual_seed(41)\n",
    ")\n",
    "\n",
    "print(\"u:\", u_data.shape)\n",
    "print(\"y:\", y_data.shape)\n",
    "print(\"s:\", s_data.shape)\n",
    "print(\"train data:\", len(train_dataset), \"test data:\", len(test_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepONet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf896e43509483b87ae7f942e728e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set train parameter\n",
    "lr = 1e-3\n",
    "batch_size = 128\n",
    "epochs = 500\n",
    "log_interval = 10\n",
    "model_name = \"DeepONet\"\n",
    "model_log = f\"{log_dir}/{model_name}/{task}\"\n",
    "\n",
    "\n",
    "model = models.DeepONet(\n",
    "    branch_layers=[num_input_sensors, 64, 64, 64, 64],\n",
    "    trunk_layers=[dim_output_sensors, 64, 64, 64, 64],\n",
    "    activation=\"relu\",\n",
    ").to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.5)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    threshold=1e-4,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "pbar = tqdm(range(epochs), desc=\"Training\")\n",
    "step = 0\n",
    "for e in pbar:\n",
    "    # Train model\n",
    "    model.train()\n",
    "    for batch_idx, (u, y, s) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        u = u.to(device)\n",
    "        y = y.to(device)\n",
    "        s = s.to(device)\n",
    "\n",
    "        preds = model((u, y))\n",
    "        loss = criterion(preds, s)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Log ouptut at each interval\n",
    "        if (step + 1) % log_interval == 0:\n",
    "            pbar.set_description(\n",
    "                \"Train Epoch(step: {:05d}): {:4d} [{:06d}/{:06d} ({:3.0f}%)] Train Loss: {:.6f}\".format(\n",
    "                    step + 1,\n",
    "                    e,\n",
    "                    batch_idx * len(u),\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                plot_u = ys[-1, :: ys.shape[1] // num_input_sensors, 0].to(device)\n",
    "                plot_y = make_mesh(xs, ts, True).to(device)\n",
    "                plot_s = ys[-1]\n",
    "                artist.plot_pde(\n",
    "                    ts,\n",
    "                    xs,\n",
    "                    plot_s,\n",
    "                    model((plot_u, plot_y)).view_as(plot_s).detach().cpu(),\n",
    "                    f\"{model_name} / Training Step: {step+1:04d}, Loss:{loss.item():.3f}\",\n",
    "                )\n",
    "                artist.save_img(f\"step_{step+1:05d}\", f\"{model_log}/imgs\")\n",
    "        step += 1\n",
    "\n",
    "    # # Test model\n",
    "    # test_loss = 0\n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     for batch_idx, (u, y, s) in enumerate(test_loader):\n",
    "    #         u = u.to(device)\n",
    "    #         y = y.to(device)\n",
    "    #         s = s.to(device)\n",
    "\n",
    "    #         preds = model((u, y))\n",
    "    #         loss = criterion(preds, s) * len(preds)\n",
    "    #         test_loss += loss.item()\n",
    "    #     # pbar.set_description(\"Test  Epoch: {:4d} Test Loss: {:.6f}\".format(e, test_loss / len(test_loader.dataset)))\n",
    "    scheduler.step(loss)\n",
    "artist.save_gif_from_files(f\"{model_name}-{task}\", model_log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepONet + Fourier Feature Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abacc6cad4574ca08144339afa18f559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set train parameter\n",
    "from src.models.model_layers import Fourier_Feature\n",
    "\n",
    "lr = 1e-4\n",
    "batch_size = 128\n",
    "epochs = 400\n",
    "log_interval = 10\n",
    "model_name = \"DeepONet\"\n",
    "model_log = f\"{log_dir}/{model_name}/{task}\"\n",
    "\n",
    "# Fourier Feature Encoding\n",
    "mapping_size = 64\n",
    "scale = 0.1\n",
    "encoding = Fourier_Feature(dim_output_sensors, mapping_size, scale)\n",
    "\n",
    "\n",
    "model = models.DeepONet(\n",
    "    branch_layers=[num_input_sensors, 64, 64, 64, 64],\n",
    "    # trunk_layers=[dim_output_sensors, 64, 64, 64, 64],\n",
    "    trunk_layers=[mapping_size, 64, 64, 64, 64, 64, 64],\n",
    "    activation=\"relu\",\n",
    ").to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.5)\n",
    "# scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "#     optimizer,\n",
    "#     mode=\"min\",\n",
    "#     factor=0.5,\n",
    "#     patience=5,\n",
    "#     threshold=1e-4,\n",
    "# )\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "pbar = tqdm(range(epochs), desc=\"Training\")\n",
    "step = 0\n",
    "for e in pbar:\n",
    "    # Train model\n",
    "    model.train()\n",
    "    for batch_idx, (u, y, s) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        u = u.to(device)\n",
    "        y = y.to(device)\n",
    "        y = encoding(y)\n",
    "        s = s.to(device)\n",
    "\n",
    "        preds = model((u, y))\n",
    "        loss = criterion(preds, s)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Log ouptut at each interval\n",
    "        if (step + 1) % log_interval == 0:\n",
    "            pbar.set_description(\n",
    "                \"Train Epoch(step: {:05d}): {:4d} [{:06d}/{:06d} ({:3.0f}%)] Train Loss: {:.6f}\".format(\n",
    "                    step + 1,\n",
    "                    e,\n",
    "                    batch_idx * len(u),\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    loss.item(),\n",
    "                )\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                plot_u = ys[-1, :: ys.shape[1] // num_input_sensors, 0].to(device)\n",
    "                plot_y = make_mesh(xs, ts, True).to(device)\n",
    "                plot_s = ys[-1]\n",
    "                artist.plot_pde(\n",
    "                    ts,\n",
    "                    xs,\n",
    "                    plot_s,\n",
    "                    # model((plot_u, plot_y)).view_as(plot_s).detach().cpu(),\n",
    "                    model((plot_u, encoding(plot_y))).view_as(plot_s).detach().cpu(),\n",
    "                    f\"{model_name} / Training Step: {step+1:04d}, Loss:{loss.item():.3f}\",\n",
    "                )\n",
    "                artist.save_img(f\"step_{step+1:05d}\", f\"{model_log}/imgs\")\n",
    "        step += 1\n",
    "\n",
    "    # # Test model\n",
    "    # test_loss = 0\n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     for batch_idx, (u, y, s) in enumerate(test_loader):\n",
    "    #         u = u.to(device)\n",
    "    #         y = y.to(device)\n",
    "    #         s = s.to(device)\n",
    "\n",
    "    #         preds = model((u, y))\n",
    "    #         loss = criterion(preds, s) * len(preds)\n",
    "    #         test_loss += loss.item()\n",
    "    #     # pbar.set_description(\"Test  Epoch: {:4d} Test Loss: {:.6f}\".format(e, test_loss / len(test_loader.dataset)))\n",
    "    # scheduler.step(loss)\n",
    "artist.save_gif_from_files(f\"{model_name}-{task}\", model_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
